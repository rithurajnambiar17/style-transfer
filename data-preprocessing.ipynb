{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image):\n",
    "    \n",
    "    # Resize the image to 256x256 pixels\n",
    "    resized_image = cv2.resize(image, (256, 256))\n",
    "    \n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    # Normalize the image\n",
    "    normalized_image = image / 255.0\n",
    "    \n",
    "    return normalized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing images!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For cubism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "original_image_dir = 'data/cubism/originalImage/'\n",
    "resized_image_dir = 'data/cubism/resizedImage/'\n",
    "\n",
    "# Get the list of all files in the originalImage directory\n",
    "all_files = os.listdir(original_image_dir)\n",
    "\n",
    "# Loop through each file\n",
    "for file_name in all_files:\n",
    "    # Construct the full path of the original image\n",
    "    original_image_path = os.path.join(original_image_dir, file_name)\n",
    "    \n",
    "    # Read the original image\n",
    "    image = cv2.imread(original_image_path)\n",
    "    \n",
    "    # Resize the image using the predefined function\n",
    "    resized_image = resize_image(image)\n",
    "    \n",
    "    # Construct the full path of the resized image\n",
    "    resized_image_path = os.path.join(resized_image_dir, file_name)\n",
    "    \n",
    "    # Save the resized and normalized image\n",
    "    cv2.imwrite(resized_image_path, resized_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Impressionism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "original_image_dir = 'data/impressionism/originalImage/'\n",
    "resized_image_dir = 'data/impressionism/resizedImage/'\n",
    "\n",
    "# Get the list of all files in the originalImage directory\n",
    "all_files = os.listdir(original_image_dir)\n",
    "\n",
    "# Loop through each file\n",
    "for file_name in all_files:\n",
    "    # Construct the full path of the original image\n",
    "    original_image_path = os.path.join(original_image_dir, file_name)\n",
    "    \n",
    "    # Read the original image\n",
    "    image = cv2.imread(original_image_path)\n",
    "    \n",
    "    # Resize the image using the predefined function\n",
    "    resized_image = resize_image(image)\n",
    "    \n",
    "    # Construct the full path of the resized image\n",
    "    resized_image_path = os.path.join(resized_image_dir, file_name)\n",
    "    \n",
    "    # Save the resized and normalized image\n",
    "    cv2.imwrite(resized_image_path, resized_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Post Impressionism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "original_image_dir = 'data/post-impressionism/originalImage/'\n",
    "resized_image_dir = 'data/post-impressionism/resizedImage/'\n",
    "\n",
    "# Get the list of all files in the originalImage directory\n",
    "all_files = os.listdir(original_image_dir)\n",
    "\n",
    "# Loop through each file\n",
    "for file_name in all_files:\n",
    "    # Construct the full path of the original image\n",
    "    original_image_path = os.path.join(original_image_dir, file_name)\n",
    "    \n",
    "    # Read the original image\n",
    "    image = cv2.imread(original_image_path)\n",
    "\n",
    "    # Resize the image using the predefined function\n",
    "    resized_image = resize_image(image)\n",
    "    \n",
    "    # Construct the full path of the resized image\n",
    "    resized_image_path = os.path.join(resized_image_dir, file_name)\n",
    "    \n",
    "    # Save the resized and normalized image\n",
    "    cv2.imwrite(resized_image_path, resized_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting the data into train and val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For cubism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles = os.listdir('data/cubism/resizedImage/')\n",
    "os.makedirs('data/cubism/train', exist_ok=True)\n",
    "os.makedirs('data/cubism/val', exist_ok=True)\n",
    "\n",
    "# Splitting percentage is training 80% and validation 20%\n",
    "splittingPercentage = 0.8\n",
    "\n",
    "# Calculate the number of files for each split\n",
    "numberOfFiles = len(allFiles)\n",
    "trainSplit = int(splittingPercentage * numberOfFiles)\n",
    "\n",
    "# Move the files into the corresponding train and validation directories\n",
    "for index, file in enumerate(allFiles):\n",
    "    if index < trainSplit:\n",
    "        shutil.move('data/cubism/resizedImage/' + file, 'data/cubism/train/')\n",
    "    else:\n",
    "        shutil.move('data/cubism/resizedImage/' + file, 'data/cubism/val/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For impressionism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles = os.listdir('data/impressionism/resizedImage/')\n",
    "os.makedirs('data/impressionism/train', exist_ok=True)\n",
    "os.makedirs('data/impressionism/val', exist_ok=True)\n",
    "\n",
    "# Splitting percentage is training 80% and validation 20%\n",
    "splittingPercentage = 0.8\n",
    "\n",
    "# Calculate the number of files for each split\n",
    "numberOfFiles = len(allFiles)\n",
    "trainSplit = int(splittingPercentage * numberOfFiles)\n",
    "\n",
    "# Move the files into the corresponding train and validation directories\n",
    "for index, file in enumerate(allFiles):\n",
    "    if index < trainSplit:\n",
    "        shutil.move('data/impressionism/resizedImage/' + file, 'data/impressionism/train/')\n",
    "    else:\n",
    "        shutil.move('data/impressionism/resizedImage/' + file, 'data/impressionism/val/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For post-impressionism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles = os.listdir('data/post-impressionism/resizedImage/')\n",
    "os.makedirs('data/post-impressionism/train', exist_ok=True)\n",
    "os.makedirs('data/post-impressionism/val', exist_ok=True)\n",
    "\n",
    "# Splitting percentage is training 80% and validation 20%\n",
    "splittingPercentage = 0.8\n",
    "\n",
    "# Calculate the number of files for each split\n",
    "numberOfFiles = len(allFiles)\n",
    "trainSplit = int(splittingPercentage * numberOfFiles)\n",
    "\n",
    "# Move the files into the corresponding train and validation directories\n",
    "for index, file in enumerate(allFiles):\n",
    "    if index < trainSplit:\n",
    "        shutil.move('data/post-impressionism/resizedImage/' + file, 'data/post-impressionism/train/')\n",
    "    else:\n",
    "        shutil.move('data/post-impressionism/resizedImage/' + file, 'data/post-impressionism/val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, losses\n",
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "class StyleTransferLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, content_weight=1, style_weight=1e5):\n",
    "        super(StyleTransferLoss, self).__init__()\n",
    "        self.content_weight = content_weight\n",
    "        self.style_weight = style_weight\n",
    "\n",
    "        # Define VGG19 with features only\n",
    "        vgg19 = VGG19(weights='imagenet', include_top=False)\n",
    "        self.vgg = tf.keras.Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
    "        self.vgg.trainable = False\n",
    "\n",
    "        self.content_loss = losses.MeanSquaredError()\n",
    "        self.style_loss = StyleLoss()\n",
    "\n",
    "    def call(self, generated, target, style_reference):\n",
    "        # Compute content loss\n",
    "        content_loss = self.content_loss(generated, target) * self.content_weight\n",
    "\n",
    "        # Compute style loss\n",
    "        style_loss = self.style_loss(generated, style_reference) * self.style_weight\n",
    "\n",
    "        total_loss = content_loss + style_loss\n",
    "        return total_loss\n",
    "\n",
    "class StyleLoss(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(StyleLoss, self).__init__()\n",
    "\n",
    "    def gram_matrix(self, x):\n",
    "        features = tf.keras.backend.batch_flatten(tf.keras.backend.permute_dimensions(x, (2, 0, 1)))\n",
    "        gram = tf.matmul(features, tf.transpose(features))\n",
    "        return gram\n",
    "\n",
    "    def call(self, generated, style_reference):\n",
    "        generated_gram = self.gram_matrix(generated)\n",
    "        style_reference_gram = self.gram_matrix(style_reference)\n",
    "        loss = tf.reduce_mean(tf.square(generated_gram - style_reference_gram))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cubism\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, UpSampling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Generator model\n",
    "def build_generator():\n",
    "    input_shape = (256, 256, 3)  # Adjust the input shape based on your requirements\n",
    "\n",
    "    model = Sequential([\n",
    "        # Upsampling block 1\n",
    "        UpSampling2D(size=(2, 2), input_shape=input_shape),\n",
    "        Conv2D(128, kernel_size=3, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "\n",
    "        # Upsampling block 2\n",
    "        UpSampling2D(size=(2, 2)),\n",
    "        Conv2D(64, kernel_size=3, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "\n",
    "        # Output block\n",
    "        Conv2D(3, kernel_size=3, padding='same', activation='tanh')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Discriminator model\n",
    "def build_discriminator():\n",
    "    input_shape = (256, 256, 3)  # Adjust the input shape based on your requirements\n",
    "\n",
    "    model = Sequential([\n",
    "        # Convolutional block 1\n",
    "        Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "\n",
    "        # Convolutional block 2\n",
    "        Conv2D(128, kernel_size=3, strides=2, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "\n",
    "        # Flatten and output\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the StyleTransferLoss as provided in the previous steps\n",
    "style_transfer_loss = StyleTransferLoss()\n",
    "\n",
    "# Combine generator and discriminator for training the generator\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # Ensure that the generator's output shape matches the input shape of the discriminator\n",
    "    noise_input = Input(shape=generator.input_shape[1:])\n",
    "    generated_image = generator(noise_input)\n",
    "    validity = discriminator(generated_image)\n",
    "\n",
    "    # Combine the generator and discriminator in a model\n",
    "    model = Model(inputs=noise_input, outputs=validity)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create instances of the models\n",
    "generator_cubism = build_generator()\n",
    "discriminator_cubism = build_discriminator()\n",
    "\n",
    "# Compile models with appropriate optimizer and loss\n",
    "optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "binary_crossentropy_loss = BinaryCrossentropy()\n",
    "\n",
    "generator_cubism.compile(optimizer=optimizer, loss=style_transfer_loss)\n",
    "discriminator_cubism.compile(optimizer=optimizer, loss=binary_crossentropy_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequential_16\" (type Sequential).\n\nInput 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 524288, but received input with shape (None, 8388608)\n\nCall arguments received by layer \"sequential_16\" (type Sequential):\n  • inputs=tf.Tensor(shape=(None, 1024, 1024, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Rithuraj\\Desktop\\GAN-style-transfer\\data-preprocessing.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Rithuraj/Desktop/GAN-style-transfer/data-preprocessing.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gan_cubism \u001b[39m=\u001b[39m build_gan(generator_cubism, discriminator_cubism)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rithuraj/Desktop/GAN-style-transfer/data-preprocessing.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m gan_cubism\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, loss\u001b[39m=\u001b[39mstyle_transfer_loss)\n",
      "\u001b[1;32mc:\\Users\\Rithuraj\\Desktop\\GAN-style-transfer\\data-preprocessing.ipynb Cell 20\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rithuraj/Desktop/GAN-style-transfer/data-preprocessing.ipynb#X40sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m noise_input \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39mgenerator\u001b[39m.\u001b[39minput_shape[\u001b[39m1\u001b[39m:])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rithuraj/Desktop/GAN-style-transfer/data-preprocessing.ipynb#X40sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m generated_image \u001b[39m=\u001b[39m generator(noise_input)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Rithuraj/Desktop/GAN-style-transfer/data-preprocessing.ipynb#X40sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m validity \u001b[39m=\u001b[39m discriminator(generated_image)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rithuraj/Desktop/GAN-style-transfer/data-preprocessing.ipynb#X40sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# Combine the generator and discriminator in a model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rithuraj/Desktop/GAN-style-transfer/data-preprocessing.ipynb#X40sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39mnoise_input, outputs\u001b[39m=\u001b[39mvalidity)\n",
      "File \u001b[1;32mc:\\Users\\Rithuraj\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Rithuraj\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\input_spec.py:280\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    275\u001b[0m             value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mvalue\n\u001b[0;32m    276\u001b[0m         \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m shape_as_list[\u001b[39mint\u001b[39m(axis)] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\n\u001b[0;32m    277\u001b[0m             value,\n\u001b[0;32m    278\u001b[0m             \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m         }:\n\u001b[1;32m--> 280\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    282\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mincompatible with the layer: expected axis \u001b[39m\u001b[39m{\u001b[39;00maxis\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof input shape to have value \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mbut received input with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape \u001b[39m\u001b[39m{\u001b[39;00mdisplay_shape(x\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m             )\n\u001b[0;32m    287\u001b[0m \u001b[39m# Check shape.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mshape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m shape\u001b[39m.\u001b[39mrank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"sequential_16\" (type Sequential).\n\nInput 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 524288, but received input with shape (None, 8388608)\n\nCall arguments received by layer \"sequential_16\" (type Sequential):\n  • inputs=tf.Tensor(shape=(None, 1024, 1024, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "gan_cubism = build_gan(generator_cubism, discriminator_cubism)\n",
    "gan_cubism.compile(optimizer=optimizer, loss=style_transfer_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
